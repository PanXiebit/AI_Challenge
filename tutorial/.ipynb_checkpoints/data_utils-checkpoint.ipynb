{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import jieba\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 英文文本正则化预处理\n",
    "def simple_token(sent):\n",
    "    sent = re.sub(r\"(\\w)'s'\\b\", r\"\\1 's\", sent)    # make 's a separate word\n",
    "    sent = re.sub(r\"(\\w[’'])(\\w)\", r\"\\1 \\2\", sent) # other ' in a word creates 2 words\n",
    "    sent = re.sub(r\"([\\\"().,;:/_?!-])\", r\" \\1 \", sent).replace('-',' ')    # add spaces around punctuation\n",
    "    sent = re.sub(r\"  *\", r\" \", sent)               # replace multiple spaces with just one\n",
    "    return sent.lower()\n",
    "\n",
    "class MySentence():\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in tqdm.tqdm(open(self.dirname)):\n",
    "            yield simple_token(line)\n",
    "            \n",
    "class MyZhSentence():\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for line in tqdm.tqdm(open(self.dirname)):\n",
    "            yield list(jieba.cut(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一对', '丹顶鹤', '正', '监视', '着', '它们', '的', '筑巢', '领地']\n",
      "['一对', '乌鸦', '飞', '到', '我们', '屋顶', '上', '的', '巢里', '，', '它们', '好像', '专门', '为拉木', '而', '来', '的', '。']\n",
      "['一对', '乖乖仔', '开着', '老爸', '的', '车子', '。']\n",
      "['一对', '九', '？', '一对', '九', '你', '就', '全', '下注', '了', '？']\n",
      "['一对二', '总', '不是', '好事', '，']\n",
      "['一对二', '，', '沃克', '传给', '波顿', '。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zh_file = \"train/train.zh\"\n",
    "zh_corpus = MyZhSentence(zh_file)\n",
    "for i,sent in enumerate(zh_corpus):\n",
    "    if i > 5:\n",
    "        break\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP]",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
